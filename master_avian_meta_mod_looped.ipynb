{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53ab763",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1f432b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this script is to read in metadata files that have clade info added already and loop through for all genes\n",
    "#to both make new columns and merge in data from files for\n",
    "#species #flyways and regions #domestic status #improved order/species groupings\n",
    "#script outputs new version of these metadata files for each gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17468a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import metadata files to modify\n",
    "HA = pd.read_csv('2023-11-28_meta_all_formerge/new_pull_avian/meta/metadata-with-clade_h5nx_ha (3).tsv', sep='\\t')\n",
    "NA = pd.read_csv('2023-11-28_meta_all_formerge/new_pull_avian/meta/metadata-with-clade_h5nx_mp.tsv', sep='\\t')\n",
    "MP = pd.read_csv('2023-11-28_meta_all_formerge/new_pull_avian/meta/metadata-with-clade_h5nx_na.tsv', sep='\\t')\n",
    "NP = pd.read_csv('2023-11-28_meta_all_formerge/new_pull_avian/meta/metadata-with-clade_h5nx_np.tsv', sep='\\t')\n",
    "NS = pd.read_csv('2023-11-28_meta_all_formerge/new_pull_avian/meta/metadata-with-clade_h5nx_ns.tsv', sep='\\t')\n",
    "PA = pd.read_csv('2023-11-28_meta_all_formerge/new_pull_avian/meta/metadata-with-clade_h5nx_pa.tsv', sep='\\t')\n",
    "PB1 = pd.read_csv('2023-11-28_meta_all_formerge/new_pull_avian/meta/metadata-with-clade_h5nx_pb1.tsv', sep='\\t')\n",
    "PB2 = pd.read_csv('2023-11-28_meta_all_formerge/new_pull_avian/meta/metadata-with-clade_h5nx_pb2.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74112f23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#check df\n",
    "HA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099b1fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make list of DFs for looping\n",
    "df_list = [HA, NA, MP, NP, NS, PA, PB1, PB2]\n",
    "df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7afb3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make empty column Animal\n",
    "for df in df_list:\n",
    "    df['Animal'] = np.nan\n",
    "list(HA.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78a89b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the 'Animal' value where the format is as expected\n",
    "for df in df_list:\n",
    "    for index, row in df.iterrows():\n",
    "        parts = row['strain'].split('/')\n",
    "        if len(parts) > 1:\n",
    "            df.at[index, 'Animal'] = parts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e98188",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in df_list:\n",
    "    df['Animal']=df['Animal'].str.lower()\n",
    "HA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a10d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing species file\n",
    "species = pd.read_csv('species.csv')\n",
    "species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddc91c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename column to match metafiles \n",
    "species = species.rename(columns={'annotated': 'Animal'})\n",
    "list(species.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518510d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "HA = pd.merge(HA, species, how='left', on=['Animal'])\n",
    "NA = pd.merge(NA, species, how='left', on=['Animal'])\n",
    "MP = pd.merge(MP, species, how='left', on=['Animal'])\n",
    "NP = pd.merge(NP, species, how='left', on=['Animal'])\n",
    "NS = pd.merge(NS, species, how='left', on=['Animal'])\n",
    "PA = pd.merge(PA, species, how='left', on=['Animal'])\n",
    "PB1 = pd.merge(PB1, species, how='left', on=['Animal'])\n",
    "PB2 = pd.merge(PB2, species, how='left', on=['Animal'])\n",
    "HA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b3de77",
   "metadata": {},
   "outputs": [],
   "source": [
    "HA=HA.drop_duplicates(subset=['strain'])\n",
    "NA=NA.drop_duplicates(subset=['strain'])\n",
    "MP=MP.drop_duplicates(subset=['strain'])\n",
    "NP=NP.drop_duplicates(subset=['strain'])\n",
    "NS=NS.drop_duplicates(subset=['strain'])\n",
    "PA=PA.drop_duplicates(subset=['strain'])\n",
    "PB1=PB1.drop_duplicates(subset=['strain'])\n",
    "PB2=PB2.drop_duplicates(subset=['strain'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19497ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##now we're gonna do the same thing to add flyways and regions\n",
    "fly_reg = pd.read_csv('flyway_regions.csv')\n",
    "fly_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ea0308",
   "metadata": {},
   "outputs": [],
   "source": [
    "HA = pd.merge(HA, fly_reg, how='left', on=['location'])\n",
    "NA = pd.merge(NA, fly_reg, how='left', on=['location'])\n",
    "MP = pd.merge(MP, fly_reg, how='left', on=['location'])\n",
    "NP = pd.merge(NP, fly_reg, how='left', on=['location'])\n",
    "NS = pd.merge(NS, fly_reg, how='left', on=['location'])\n",
    "PA = pd.merge(PA, fly_reg, how='left', on=['location'])\n",
    "PB1 = pd.merge(PB1, fly_reg, how='left', on=['location'])\n",
    "PB2 = pd.merge(PB2, fly_reg, how='left', on=['location'])\n",
    "HA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda8e935",
   "metadata": {},
   "outputs": [],
   "source": [
    "HA.loc[HA['location'] == 'Massachusetts']\n",
    "#test to see that this worked bc can't see NorthAm strains is preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97de866b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop duplicates again and check\n",
    "HA=HA.drop_duplicates(subset=['strain'])\n",
    "NA=NA.drop_duplicates(subset=['strain'])\n",
    "MP=MP.drop_duplicates(subset=['strain'])\n",
    "NP=NP.drop_duplicates(subset=['strain'])\n",
    "NS=NS.drop_duplicates(subset=['strain'])\n",
    "PA=PA.drop_duplicates(subset=['strain'])\n",
    "PB1=PB1.drop_duplicates(subset=['strain'])\n",
    "PB2=PB2.drop_duplicates(subset=['strain'])\n",
    "HA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c49d742",
   "metadata": {},
   "outputs": [],
   "source": [
    "#next merging- for domestic status, first need to read in file with this data\n",
    "#importing Lambo's tsv with the metadata columns of interest\n",
    "LDmeta = pd.read_csv('NA-H5Nx-2021-2023-seqmerge.tsv', sep='\\t')\n",
    "LDmeta.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7358ebb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to modify the id column to remove dashes so it will match the other metadata file\n",
    "LDmeta['ID'] = LDmeta['ID'].str.replace('-','')\n",
    "LDmeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960f8ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now want to drop a bunch of unnecessary/redundant columns so the merge isn't crazy\n",
    "LDmeta = LDmeta.drop(columns=[\n",
    "    'seq', 'ID-22rem', 'Location', 'Note', 'State_Province', \n",
    "    'Clade', 'city_county', 'Host', 'Collection_Date', 'Unnamed: 0'])\n",
    "list(LDmeta.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f7a125",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#clean up the namings for domestic status\n",
    "LDmeta[\"Domestic_Status\"] = LDmeta[\"Domestic_Status\"].apply(lambda x: x.replace(\"nonhuman_mammal\", \"Nonhuman Mammal\"))\n",
    "LDmeta.loc[LDmeta['Domestic_Status'] == 'Nonhuman Mammal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fe81c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean up the namings for domestic status\n",
    "LDmeta[\"Domestic_Status\"] = LDmeta[\"Domestic_Status\"].apply(lambda x: x.replace(\"Backyard bird\", \"Backyard Bird\"))\n",
    "LDmeta.loc[LDmeta['Domestic_Status'] == 'Backyard Bird']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87d63ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "LDmeta[\"Domestic_Status\"] = LDmeta[\"Domestic_Status\"].apply(lambda x: x.replace(\"U\", \"Unknown\"))\n",
    "LDmeta.loc[LDmeta['Domestic_Status'] == 'Unknown']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4bbc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "##need to update DFs in DF list\n",
    "df_list = [HA, NA, MP, NP, NS, PA, PB1, PB2]\n",
    "df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ef1ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in df_list:\n",
    "    df['ID'] = np.nan\n",
    "list(HA.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fcefc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make ID column from pulling out ID from strain name to match on \n",
    "for df in df_list:\n",
    "    split_values = df['strain'].str.split('/')  # 'strain' is the column to split\n",
    "    df['ID'] = split_values.str[3]\n",
    "    \n",
    "#for df in df_list:\n",
    "    #for index, row in df.iterrows():\n",
    "       # parts = row['strain'].split('/')\n",
    "       # if len(parts) > 1:\n",
    "          #  df.at[index, 'ID'] = parts[2]\n",
    "HA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ebb633",
   "metadata": {},
   "outputs": [],
   "source": [
    "PB2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d524bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "HA = pd.merge(HA, LDmeta, how='left', on=['ID'])\n",
    "NA = pd.merge(NA, LDmeta, how='left', on=['ID'])\n",
    "MP = pd.merge(MP, LDmeta, how='left', on=['ID'])\n",
    "NP = pd.merge(NP, LDmeta, how='left', on=['ID'])\n",
    "NS = pd.merge(NS, LDmeta, how='left', on=['ID'])\n",
    "PA = pd.merge(PA, LDmeta, how='left', on=['ID'])\n",
    "PB1 = pd.merge(PB1, LDmeta, how='left', on=['ID'])\n",
    "PB2 = pd.merge(PB2, LDmeta, how='left', on=['ID'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b496a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "HA.loc[HA['region'] == 'North America']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6741dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(HA.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0ecdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# updating DF list just in case those aren't linked with up to date dfs- should look into how this works\n",
    "##need to update DFs in DF list\n",
    "df_list = [HA, NA, MP, NP, NS, PA, PB1, PB2]\n",
    "df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ec8c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in df_list:\n",
    "    \n",
    "   df.drop(columns=['state2','broad','correction','Isolate_Id', \n",
    "                    'Isolate_Name'], inplace=True)\n",
    "\n",
    "list(HA.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d63919",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create list for the missing orders\n",
    "\n",
    "carnivore_list = ['skunk', 'redfox', 'fox', 'bobcat', 'harborseal', 'raccoon', \n",
    "                  'blackbear', 'stripedskunk', 'cat', 'vulpesvulpes', 'coyote',\n",
    "                  'greyseal', 'wildmink']\n",
    "marsup_list = ['virginiaopossum']\n",
    "artiodactyl_list = ['bottlenosedolphin','dolphin']\n",
    "anseriformes_list = ['lesserscaup']\n",
    "passeriformes_list = ['greattailedgrackle', 'americanraven']\n",
    "pelican_list = ['brownpelican', 'snowyegret']\n",
    "accipitriformes_list = ['osprey', 'turkeyvulture', 'coopershawk']\n",
    "\n",
    "for df in df_list:\n",
    "\n",
    "    df.loc[df['Animal'].isin(carnivore_list), 'order'] = 'carnivora'\n",
    "    df.loc[df['Animal'].isin(marsup_list), 'order'] = 'didelphimorphia'\n",
    "    df.loc[df['Animal'].isin(artiodactyl_list), 'order'] = 'artiodactyl'\n",
    "    df.loc[df['Animal'].isin(anseriformes_list), 'order'] = 'anseriformes'\n",
    "    df.loc[df['Animal'].isin(passeriformes_list), 'order'] = 'passeriformes'\n",
    "    df.loc[df['Animal'].isin(pelican_list), 'order'] = 'pelecaniformes'\n",
    "    df.loc[df['Animal'].isin(accipitriformes_list), 'order'] = 'accipitriformes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11891e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#confirm\n",
    "carnivores = PB2.loc[PB2['order'] == 'carnivora']\n",
    "\n",
    "print(carnivores[['Animal','order']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f377b73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding a couple missing animals to wild designation for domestic status via the same list method\n",
    "\n",
    "wild_list = ['blackvulture', 'commontern']\n",
    "\n",
    "for df in df_list:\n",
    "\n",
    "    df.loc[df['Animal'].isin(wild_list), 'Domestic_Status'] = 'Wild'\n",
    "    \n",
    "print(HA.loc[HA['Animal'] == 'blackvulture'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6b34a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new empty column now named species group for grouping some orders together\n",
    "for df in df_list:\n",
    "\n",
    "    df['species_group'] = np.nan\n",
    "list(HA.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe96c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "terrest_list = ['skunk', 'redfox', 'fox', 'bobcat', 'raccoon', \n",
    "                'blackbear', 'stripedskunk', 'cat', 'vulpesvulpes', 'coyote',\n",
    "                'wildmink']\n",
    "marine_list = ['harborseal', 'greyseal','bottlenosedolphin','dolphin']\n",
    "\n",
    "for df in df_list:\n",
    "\n",
    "    df.loc[df['Animal'].isin(terrest_list), 'species_group'] = 'Mammal- Terrestrial'\n",
    "    df.loc[df['Animal'].isin(marine_list), 'species_group'] = 'Mammal- Marine'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d62c9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "anser_list = ['anseriformes']\n",
    "gall_list = ['galliformes']\n",
    "raptor_list = ['accipitriformes', 'falconiformes', 'strigiformes']\n",
    "waterbird_list = ['charadriiformes', 'pelecaniformes', 'suliformes', 'podicipediformes']\n",
    "passer_list = ['passeriformes']\n",
    "other_avian_list = ['casuariiformes', 'rheiformes', 'avian']\n",
    "\n",
    "for df in df_list:\n",
    "\n",
    "    df.loc[df['order'].isin(anser_list), 'species_group'] = 'Anseriformes'\n",
    "    df.loc[df['order'].isin(gall_list), 'species_group'] = 'Galliformes'\n",
    "    df.loc[df['order'].isin(raptor_list), 'species_group'] = 'Raptor'\n",
    "    df.loc[df['order'].isin(waterbird_list), 'species_group'] = 'Other- Waterbird'\n",
    "    df.loc[df['order'].isin(passer_list), 'species_group'] = 'Passerine'\n",
    "    df.loc[df['order'].isin(other_avian_list), 'species_group'] = 'Other- Avian'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d05825",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = PB2.loc[PB2['species_group'] == 'Mammal- Terrestrial']\n",
    "\n",
    "print(test[['order','species_group']].head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9578411",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export, indicating file path to separate output folder\n",
    "\n",
    "HA.to_csv('output_tsvs/merged_meta_ha_12-15.tsv', sep=\"\\t\") \n",
    "NA.to_csv('output_tsvs/merged_meta_na_12-15.tsv', sep=\"\\t\") \n",
    "MP.to_csv('output_tsvs/merged_meta_mp_12-15.tsv', sep=\"\\t\") \n",
    "NS.to_csv('output_tsvs/merged_meta_ns_12-15.tsv', sep=\"\\t\") \n",
    "NP.to_csv('output_tsvs/merged_meta_np_12-15.tsv', sep=\"\\t\") \n",
    "PA.to_csv('output_tsvs/merged_meta_pa_12-15.tsv', sep=\"\\t\") \n",
    "PB1.to_csv('output_tsvs/merged_meta_pb1_12-15.tsv', sep=\"\\t\") \n",
    "PB2.to_csv('output_tsvs/merged_meta_pb2_12-15.tsv', sep=\"\\t\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
